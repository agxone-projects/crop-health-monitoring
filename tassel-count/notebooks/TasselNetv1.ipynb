{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TasselNetv1.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "133yoQa8fPri"
      },
      "source": [
        "#### Setting up the Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ftm24cOU-ah"
      },
      "source": [
        "%%capture\n",
        "!pip install pyyaml==5.1\n",
        "!pip install sklearn funcy argparse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y40tNRWWehQR"
      },
      "source": [
        "import torch, torchvision\n",
        "assert torch.__version__.startswith(\"1.8\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5W78zEWfelpy"
      },
      "source": [
        "# %%capture\n",
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.9/index.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEQhaRVweoQH"
      },
      "source": [
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaG1LZqOeriu"
      },
      "source": [
        "import numpy as np\n",
        "import os, json, cv2, random, glob, tqdm, math\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TxMjWbwfWHj"
      },
      "source": [
        "#### Creating the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIaymtGDravl"
      },
      "source": [
        "from PIL import Image, ImageDraw, ImageOps\n",
        "from skimage import measure\n",
        "from pycocotools import mask as pymask\n",
        "import json\n",
        "!pip install imantics\n",
        "from imantics import Polygons, Mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvU0DWC_C83_"
      },
      "source": [
        "def get_crop_boxes(xys, boxSize, crop):\n",
        "  x1,y1,x2,y2 = crop\n",
        "  crop_boxes = []\n",
        "  for xy in xys:\n",
        "    x0, y0 = xy\n",
        "    if (x1 <= x0 <= x2) and (y1 <= y0 <= y2):\n",
        "      bx1, by1 = (x0 - boxSize / 2),  (y0 - boxSize / 2)\n",
        "      bx2, by2 = bx1 + boxSize, by1 + boxSize\n",
        "      if bx1 < x1:\n",
        "        bx1 = x1\n",
        "      if by1 < y1:\n",
        "        by1 = y1\n",
        "      if bx2 > x2:\n",
        "        bx2 = x2\n",
        "      if by2 > y2:\n",
        "        by2 = y2\n",
        "      crop_boxes.append([bx1-x1, by1 - y1, bx2 - bx1, by2 - by1]) #in x1y1wh format\n",
        "  return crop_boxes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-VnH_be_mbf"
      },
      "source": [
        "def myconverter(obj):\n",
        "  if isinstance(obj, np.integer):\n",
        "      return int(obj)\n",
        "  elif isinstance(obj, np.floating):\n",
        "      return float(obj)\n",
        "  elif isinstance(obj, np.ndarray):\n",
        "      return obj.tolist()\n",
        "  elif isinstance(obj, datetime.datetime):\n",
        "      return obj.__str__()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIvIqAGUfK4C"
      },
      "source": [
        "def create_crops_annos(data_dir, crop_size, dest_dir, boxSize = 30):\n",
        "  all_files = os.listdir(data_dir)\n",
        "  img_files = [os.path.join(data_dir,f) for f in all_files if f.endswith('.tif')]\n",
        "  xy_files = [os.path.join(data_dir,f) for f in all_files if f.endswith('.txt')]\n",
        "  img_files.sort()\n",
        "  xy_files.sort()\n",
        "  new_anno_dict = {\"images\":[], \n",
        "                   \"annotations\":[],\n",
        "                   \"categories\": [{\n",
        "                      \"id\": 1,\n",
        "                      \"name\": \"tassel\",\n",
        "                      \"supercategory\": \"tassel\",\n",
        "                      \"color\": \"#0bbdcc\"\n",
        "                   }]}\n",
        "\n",
        "  crop_id = 1\n",
        "  anno_id = 1\n",
        "  for x in range(len(img_files)):\n",
        "    img = cv2.imread(img_files[x])\n",
        "    img_height, img_width = img.shape[:2]\n",
        "\n",
        "    label_file = open(xy_files[x],'r')\n",
        "    xys = [list(map(float, line.split())) for line in label_file]\n",
        "    # boxes = [xy_to_xyxy(xy, 30, img_width, img_height) for xy in xys]\n",
        "\n",
        "    for i in range(img_height // crop_size):\n",
        "      for j in range(img_width // crop_size):\n",
        "        x1, y1 = (crop_size * j), (crop_size * i)\n",
        "        x2, y2 = (x1 + crop_size), (y1 + crop_size)\n",
        "        \n",
        "        crop = img[y1:y2,x1:x2]\n",
        "        crop_boxes = get_crop_boxes(xys, boxSize, [x1, y1, x2, y2])\n",
        "        \n",
        "        crop_image = {\n",
        "          \"id\" : crop_id,\n",
        "          \"category_ids\": [1],\n",
        "          \"width\": crop_size,\n",
        "          \"height\": crop_size,\n",
        "          \"file_name\": f'crop_{x}_{i}_{j}.jpg',\n",
        "          \"num_annotations\": len(crop_boxes)\n",
        "        }\n",
        "        new_anno_dict[\"images\"].append(crop_image)\n",
        "        cv2.imwrite(f'{dest_dir}/crop_{x}_{i}_{j}.jpg', crop)\n",
        "\n",
        "        for box in crop_boxes:\n",
        "          crop_annotation = {\n",
        "            \"id\": anno_id,\n",
        "            \"bbox\": box,\n",
        "            \"image_id\": crop_id,\n",
        "            \"segmentation\": [],\n",
        "            \"area\": box[2]*box[3],\n",
        "            \"iscrowd\": 0,\n",
        "            \"category_id\": 1\n",
        "          }\n",
        "          new_anno_dict[\"annotations\"].append(crop_annotation)\n",
        "          anno_id += 1\n",
        "        crop_id += 1\n",
        "  with open(f'{dest_dir}/annotations.json', 'wt', encoding='UTF-8') as anno_file:\n",
        "    json.dump(new_anno_dict, anno_file, indent=2, sort_keys=True, default=myconverter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUZdcY1Y7Y9W"
      },
      "source": [
        "!mkdir dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciAnPSftkQOL"
      },
      "source": [
        "create_crops_annos('/content/drive/MyDrive/TasselNetv1/data', 150, '/content/dataset')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aN2N1QeDAZSa"
      },
      "source": [
        "#### Splitting the dataset into Train Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7fZHEmuAj01"
      },
      "source": [
        "import json\n",
        "import argparse\n",
        "import funcy\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def save_coco(file, images, annotations, categories):\n",
        "  with open(file, 'wt', encoding='UTF-8') as coco:\n",
        "    json.dump({'images': images, \n",
        "      'annotations': annotations, 'categories': categories}, coco, indent=2, sort_keys=True)\n",
        "    \n",
        "def filter_annotations(annotations, images):\n",
        "  image_ids = funcy.lmap(lambda i: int(i['id']), images)\n",
        "  return funcy.lfilter(lambda a: int(a['image_id']) in image_ids, annotations)\n",
        "\n",
        "def split_coco_annotation(annotations, split_ratio, train_json, test_json, is_having = True):\n",
        "  with open(annotations, 'rt', encoding='UTF-8') as anno:\n",
        "    coco = json.load(anno)\n",
        "    images = coco['images']\n",
        "    annotations = coco['annotations']\n",
        "    categories = coco['categories']\n",
        "\n",
        "    images_with_annotations = funcy.lmap(lambda a: int(a['image_id']), annotations)\n",
        "\n",
        "    if is_having:\n",
        "        images = funcy.lremove(lambda i: i['id'] not in images_with_annotations, images)\n",
        "\n",
        "    x, y = train_test_split(images, train_size = split_ratio)\n",
        "\n",
        "    save_coco(train_json, x, filter_annotations(annotations, x), categories)\n",
        "    save_coco(test_json, y, filter_annotations(annotations, y), categories)\n",
        "\n",
        "    print(\"Saved {} entries in {} and {} in {}\".format(len(x), train_json, len(y), test_json))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9U7Fu-4WA2UT"
      },
      "source": [
        "split_coco_annotation('/content/dataset/annotations.json', 0.6, \n",
        "                      '/content/dataset/train_annotations.json', '/content/dataset/test_annotations.json')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZFrZdxxBENM"
      },
      "source": [
        "#### Registering the Dataset to the Detectron and Checking the Annotations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrAWv4LGBCHR"
      },
      "source": [
        "from detectron2.data.datasets import register_coco_instances\n",
        "register_coco_instances(f\"tassel_train\", {}, '/content/dataset/train_annotations.json', \"/content/dataset\")\n",
        "register_coco_instances(f\"tassel_test\", {}, '/content/dataset/test_annotations.json', \"/content/dataset\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3zaiQ2zBNqN"
      },
      "source": [
        "tassel_metadata = MetadataCatalog.get(f\"tassel_train\")\n",
        "train_dataset_dicts = DatasetCatalog.get(f\"tassel_train\")\n",
        "test_dataset_dicts = DatasetCatalog.get(f\"tassel_test\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKg-Dj7UBU9G"
      },
      "source": [
        "import random\n",
        "from detectron2.utils.visualizer import ColorMode\n",
        "\n",
        "for d in random.sample(test_dataset_dicts, 10):\n",
        "    print(d[\"file_name\"])\n",
        "    img = cv2.imread(d[\"file_name\"])\n",
        "    visualizer = Visualizer(img[:, :, ::-1], metadata=tassel_metadata, scale=1, instance_mode=ColorMode.IMAGE_BW)\n",
        "    vis = visualizer.draw_dataset_dict(d)\n",
        "    cv2_imshow(vis.get_image()[:, :, ::-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbjPF-lHCOPw"
      },
      "source": [
        "# !unzip /content/drive/MyDrive/TasselNetv1/Maize_Tassel_Counting_Dataset.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEwpeI_iDBB_"
      },
      "source": [
        "# import scipy.io\n",
        "# mat = scipy.io.loadmat('/content/Maize Tassel Counting Dataset/Taian2012_1/Annotations/T0001_XM_20120808090256_01.mat')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wdk8-ULEJBR"
      },
      "source": [
        "# mat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEOj5_TPDJ8N"
      },
      "source": [
        "# mat['annotation'].tolist()[0][0][1].tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkT1CCIZBppO"
      },
      "source": [
        "#### Training using Faster RCNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdDvrWimBcgG"
      },
      "source": [
        "%%capture\n",
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.config import get_cfg\n",
        "import os\n",
        "\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.DATASETS.TRAIN = (\"tassel_train\",)\n",
        "cfg.DATASETS.TEST = ()\n",
        "cfg.DATALOADER.NUM_WORKERS = 4\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")\n",
        "cfg.SOLVER.IMS_PER_BATCH = 10\n",
        "cfg.SOLVER.BASE_LR = 0.002\n",
        "cfg.SOLVER.MAX_ITER = 2000\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
        "\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "trainer = DefaultTrainer(cfg)\n",
        "trainer.resume_or_load(resume=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXHy5Ei46QGy"
      },
      "source": [
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pJuegnoCHcj"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdiyyTY2E9yH"
      },
      "source": [
        "#### Trying the Model on Testset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6A6rwNhE5bW"
      },
      "source": [
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.8 \n",
        "predictor = DefaultPredictor(cfg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_mXxTiUF7cO"
      },
      "source": [
        "from detectron2.utils.visualizer import ColorMode\n",
        "\n",
        "for d in random.sample(test_dataset_dicts, 5): \n",
        "  print(d['file_name']) \n",
        "  im = cv2.imread(d['file_name'])\n",
        "  outputs = predictor(im)\n",
        "  v = Visualizer(im[:, :, ::-1],\n",
        "                  metadata=tassel_metadata, \n",
        "                  scale=2, \n",
        "                  instance_mode=ColorMode.IMAGE_BW\n",
        "  )\n",
        "  v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "  cv2_imshow(v.get_image()[:, :, ::-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b02XwLIxkvTh"
      },
      "source": [
        "#### Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RY1RdT2ktwJ"
      },
      "source": [
        "def get_tassels(img, predictor, crop_size = 150):\n",
        "  num_tassels = 0\n",
        "  img_height, img_width = img.shape[:2]\n",
        "  tassels_img = Image.new('RGB', (img_width // crop_size * crop_size, img_height // crop_size * crop_size))\n",
        "  for i in range(img_height // crop_size):\n",
        "    for j in range(img_width // crop_size):\n",
        "      x1, y1 = (crop_size * j), (crop_size * i)\n",
        "      x2, y2 = (x1 + crop_size), (y1 + crop_size)\n",
        "      crop = img[y1:y2,x1:x2]\n",
        "      output = predictor(crop)\n",
        "      boxes = outputs['instances'].get_fields()['pred_boxes'].tensor.tolist()\n",
        "      num_tassels += len(boxes)\n",
        "      tassels_crop = Visualizer(crop[:, :, ::-1],\n",
        "                metadata=tassel_metadata, \n",
        "                scale=1, \n",
        "                instance_mode=ColorMode.IMAGE_BW\n",
        "      )\n",
        "      tassels_crop = tassels_crop.draw_instance_predictions(output[\"instances\"].to(\"cpu\"))\n",
        "      tassels_crop = tassels_crop.get_image()[:, :, ::-1]\n",
        "      tassels_img.paste(Image.fromarray(tassels_crop),(j* crop_size, i * crop_size))\n",
        "  return num_tassels, np.array(tassels_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQjfdQ-xGDTz"
      },
      "source": [
        "im = cv2.imread('/content/drive/MyDrive/TasselNetv1/data/Crop2.tif')\n",
        "num_tassels, tassels_img = get_tassels(im, predictor, 150)\n",
        "# outputs = predictor(im)\n",
        "# v = Visualizer(im[:, :, ::-1],\n",
        "#                 metadata=tassel_metadata, \n",
        "#                 scale=2, \n",
        "#                 instance_mode=ColorMode.IMAGE_BW\n",
        "# )\n",
        "# v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "# cv2_imshow(v.get_image()[:, :, ::-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Syq023YWl2nA"
      },
      "source": [
        "num_tassels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mP1IL9S1sBZA"
      },
      "source": [
        "cv2_imshow(tassels_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04nbSoE_sILl"
      },
      "source": [
        "!cp -R /content/output/model_final.pth /content/drive/MyDrive/TasselNetv1/model_final.pth"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKx9JpWOL1vh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}