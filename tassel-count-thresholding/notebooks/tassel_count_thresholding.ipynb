{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tassel-count-thresholding.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVI-hLZGy8g6"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from skimage.segmentation import watershed\n",
        "from skimage.feature import peak_local_max\n",
        "from scipy import ndimage\n",
        "import matplotlib.pyplot as plt\n",
        "import argparse\n",
        "import glob\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fC81ntJhzC2j"
      },
      "source": [
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2Jf8HmmQSvF"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKM1bD8WzIGQ"
      },
      "source": [
        "def hsv_threshold(img, min_hsv_val, max_hsv_val):\n",
        "    \"\"\"Return a binary mask with the pixels within the specified HSV color range.\"\"\"\n",
        "    # remove background dark area\n",
        "    img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "    mask_init = np.expand_dims(np.prod(img[:, :, :] > 40, axis=2).astype(np.uint8), 2)\n",
        "    mask_hsv = mask_init * img_hsv\n",
        "    \n",
        "    # create hsv range\n",
        "    min_val = np.array(min_hsv_val)\n",
        "    max_val = np.array(max_hsv_val)\n",
        "    \n",
        "    # creat mask of values fall inside\n",
        "    mask = cv2.inRange(mask_hsv, min_val, max_val)\n",
        "    mask = (mask == 255).astype(np.uint8)\n",
        "    return mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3r9hebizK3m"
      },
      "source": [
        "def opening_morph(mask, kernel_size = 5):\n",
        "    \"\"\"Perform opening morphological operation on binary mask.\"\"\"\n",
        "\n",
        "    ker_size_erode = kernel_size\n",
        "    ker_size_dilate = kernel_size\n",
        "    \n",
        "    # create kernels for erosion & dilation\n",
        "    kernel_erode = np.ones((ker_size_erode, ker_size_erode), np.uint8)\n",
        "    kernel_dilate = np.ones((ker_size_dilate, ker_size_dilate), np.uint8)\n",
        "    \n",
        "    # perform opening morphological operation\n",
        "    mask_eroded = cv2.erode(mask, kernel_erode)\n",
        "    mask_eroded_dilated = cv2.dilate(mask_eroded, kernel_dilate)\n",
        "    return mask_eroded_dilated"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YuzAD1wzMpV"
      },
      "source": [
        "def watershed_segmentation(thresh_mask):\n",
        "    \"\"\"Perform watershed segmentation on a thresholded mask. Returns 2D array of segment labels, each with a unique integer.\"\"\"\n",
        "    \n",
        "    # compute EDT distance map\n",
        "    distance_map = ndimage.distance_transform_edt(thresh_mask)\n",
        "    \n",
        "    # perform a connected component analysis on the local peaks,\n",
        "    # using 8-connectivity, then appy the Watershed algorithm\n",
        "    local_maximas = peak_local_max(distance_map, indices=False, min_distance=2,\n",
        "     \tlabels=thresh_mask)\n",
        "    \n",
        "    markers, num_features = ndimage.label(local_maximas, structure=np.ones((3, 3)))\n",
        "    labels = watershed(-distance_map,markers,mask=thresh_mask)\n",
        "    return labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "602HMIFizOTF"
      },
      "source": [
        "def filter_contours(contours, min_area = 20):\n",
        "    \"\"\"Filter out contours with insignificant area.\"\"\"\n",
        "    \n",
        "    if not isinstance(contours, np.ndarray):\n",
        "        new_contours = np.array(contours)\n",
        "    \n",
        "    # find area of each contour\n",
        "    areas = list(map(cv2.contourArea,contours))\n",
        "    areas = np.array(areas)\n",
        "    \n",
        "    # remove contours with small area\n",
        "    proper_cnts = new_contours[areas > min_area]\n",
        "    return proper_cnts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZaMMezzzQYQ"
      },
      "source": [
        "def center_of_mass(M):\n",
        "    \"\"\"Return center of mass of an area.\"\"\"\n",
        "    \n",
        "    cx = int(M['m10']/M['m00'])\n",
        "    cy = int(M['m01']/M['m00'])\n",
        "    return [cx,cy]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3q-HY3vzR_z"
      },
      "source": [
        "def plot_centers(centers, img):\n",
        "    \"\"\"Plot center points on the original image\"\"\"\n",
        "    \n",
        "    x,y = np.transpose(centers)\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    plt.figure(figsize=(20,10))\n",
        "    plt.imshow(img_rgb)\n",
        "    plt.scatter(x,y,s=15, c='red', marker='o')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRqQHNPhzTwu"
      },
      "source": [
        "def write_centers_to_file(centers, filepath):\n",
        "    \"\"\"Write center coordinates to txt file.\"\"\"\n",
        "    \n",
        "    with open(filepath, 'w') as f:\n",
        "        for item in centers:\n",
        "            f.write(f\"{item[0]} {item[1]}\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Llx4-WBBAk8x"
      },
      "source": [
        "def main(img_path, annotation_path=None, verbosity=2):\n",
        "    \"\"\"Find corn plants in aerial image, create annotation file.\"\"\"\n",
        "    \n",
        "    # load image\n",
        "    img = cv2.imread(img_path)\n",
        "    \n",
        "    # remove background\n",
        "    min_val = [30, 0, 100] # hsv value\n",
        "    max_val = [65, 255, 255] # hsv value\n",
        "    thresh_mask = hsv_threshold(img, min_val, max_val)\n",
        "    if verbosity>1:\n",
        "        cv2_imshow(cv2.resize(thresh_mask*255,(0,0),fx=0.5,fy=0.5))\n",
        "    \n",
        "    # remove noise from the thresholded mask\n",
        "    opened_mask = opening_morph(thresh_mask, kernel_size = 3)\n",
        "    if verbosity>1:\n",
        "        cv2_imshow(cv2.resize(opened_mask*255,(0,0),fx=0.5,fy=0.5))\n",
        "    \n",
        "    # find contours of tassel blobs\n",
        "    contours, hierarchy = cv2.findContours(image=opened_mask.copy(), mode=cv2.RETR_EXTERNAL,\n",
        "                                           method=cv2.CHAIN_APPROX_NONE)\n",
        "    if verbosity>0:\n",
        "        print(\"Identified number of crops:{}\".format(len(contours)))\n",
        "    \n",
        "    # perform watershed segmentation to separate combined tassel blobs\n",
        "    watershed_labels = watershed_segmentation(opened_mask*255)\n",
        "    \n",
        "    # loop over the unique labels returned by the Watershed algorithm\n",
        "    new_contours= []\n",
        "    for label in np.unique(watershed_labels):\n",
        "     \t# if the label is zero, we are examining the 'background'\n",
        "     \t# so simply ignore it\n",
        "     \tif label == 0:\n",
        "             continue\n",
        "     \t# otherwise, allocate memory for the label region and draw\n",
        "     \t# it on the mask\n",
        "     \tmask = np.zeros(img.shape[:2], dtype=\"uint8\")\n",
        "     \tmask[watershed_labels == label] = 255\n",
        "     \t# detect contours in the mask and grab the largest one\n",
        "     \tcnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL,\n",
        "    \t\tcv2.CHAIN_APPROX_SIMPLE)[0]\n",
        "     \tnew_contours.extend(cnts)\n",
        "\n",
        "    # display all contours\n",
        "    if verbosity>1:\n",
        "        cnt_img = cv2.drawContours(img.copy(),new_contours,-1,(0,0,255),1)\n",
        "        cv2_imshow(cnt_img)\n",
        "    \n",
        "    # find filtered contours\n",
        "    filtered_cnts = filter_contours(new_contours, min_area=15)\n",
        "    \n",
        "    # display filtered contours\n",
        "    if verbosity>1:\n",
        "        cnt_img = cv2.drawContours(img.copy(),filtered_cnts,-1,(0,0,255),1)\n",
        "        cv2_imshow(cnt_img)\n",
        "    if verbosity>0:\n",
        "        print('number of corn plants identified using watershed: ', len(filtered_cnts))\n",
        "    \n",
        "    # find center of mass of contours\n",
        "    moments = map(cv2.moments,filtered_cnts)\n",
        "    centers = np.array(list(map(center_of_mass,moments)))\n",
        "    if verbosity>1:\n",
        "        plot_centers(centers, img)\n",
        "    \n",
        "    # create txt files for corresponding images and include centers' coordinates\n",
        "    if not annotation_path:\n",
        "      annotation_path = \".\".join(img_path.split(\".\")[:-1])+\".txt\"\n",
        "    write_centers_to_file(centers, annotation_path)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPt5ohO-0JPH"
      },
      "source": [
        "The code below will run the algorithm on all images in the path, find coordinates of corn tassels, and write them to an annotation file (one per image)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TccSXuSoze54"
      },
      "source": [
        "if __name__==\"__main__\":\n",
        "  # parser = argparse.ArgumentParser()\n",
        "  # parser.add_argument(\"-i\", \"--image\", required=True, help=\"path to input image\")\n",
        "  # parser.add_argument(\"-v\",\"--verbose\", action=\"count\", help=\"verbosity level\")\n",
        "  # args = parser.parse_args()\n",
        "  # main(parser.image, parser.verbose)\n",
        "\n",
        "  # Enter appropriate path to images (place forward slash at the end)\n",
        "  images_path = \"/content/drive/MyDrive/CornNet_v2/outputs_800/outputs/\" \n",
        "  all_images = glob.glob(images_path+ \"*\")\n",
        "  # images = random.sample(all_images,10)\n",
        "\n",
        "  for image in all_images:\n",
        "    main(image, f\"{image.split('/')[-1][:-3]+'txt'}\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}